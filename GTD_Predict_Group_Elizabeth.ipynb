{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTD prediction model\n",
    "Use attack type, weapons used, description of the attack, etc. to build a model that can predict what group may have been responsible for an incident.\n",
    "\n",
    "* The prediction model used: random forest classifier\n",
    "* special feature: spatial clustering to identify terrorism hotspots\n",
    "    * terrorism can crop in regions that are not well described by borders\n",
    "    * used latitude and longitude of attacks to identify high density areas of attacks\n",
    "    * assigned every attack to a hotspot\n",
    "* data selection: \n",
    "    * did not use 30% or greater missing features\n",
    "    * combined parameters to reduce feature space\n",
    "* memory workarounds:\n",
    "    * predictive model iterated on subsets of data\n",
    "    * optimized tree depth\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the library with the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Load pandas\n",
    "import pandas as pd\n",
    "# Load numpy\n",
    "import numpy as np\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mycol=pd.read_csv(\"rawdata/col_index.txt\",delim_whitespace=1)\n",
    "myindex=list(np.array([int(i) for i in list(mycol)])-1)+[13,14] #add latitude longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rawdata/globalterrorismdb_0617dist.csv\",encoding='ISO-8859-1',usecols=myindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inspection and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) convert datatypes to category, numeric, integer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convert_to_cat=[\"extended\",\n",
    "                \"country_txt\",\"region_txt\",\"provstate\",\n",
    "                \"crit1\",\"crit2\",\"crit3\",\"doubtterr\",\n",
    "                \"suicide\",\"attacktype1_txt\",\"targtype1_txt\",\"natlty1_txt\",\n",
    "                \"gname\",\"guncertain1\",\"individual\",\"weaptype1_txt\",\n",
    "               \"property\",\"ishostkid\",\n",
    "                \"INT_LOG\",\"INT_IDEO\",\"INT_MISC\",\"INT_ANY\"]\n",
    "\n",
    "\n",
    "convert_to_float=[\"extended\",\"nkill\",\"nwound\",\"latitude\",\"longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['iday', 'imonth','iyear']] = df[['iday', 'imonth','iyear']].astype(int)\n",
    "\n",
    "for thecol in convert_to_cat:\n",
    "    df[thecol]=df[thecol].astype('category')\n",
    "for thecol in convert_to_float:\n",
    "    df[thecol]=df[thecol].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) calculate new columns from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"datetime\"]=pd.to_datetime(df[\"iday\"],df[\"imonth\"],df[\"iyear\"])\n",
    "df=df.drop('iday',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df['imonth']=df['imonth'].astype('category')\n",
    "#df['iyear']=df['iyear'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['nwound'].fillna(0).astype(int)\n",
    "df['nkill'].fillna(0).astype(int)\n",
    "df['ncasualities']=df['nkill']+df['nwound']\n",
    "df=df.drop(['nwound','nkill'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) summarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfsumcat=df.describe(include=['category'])\n",
    "dfsumcat.iloc[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfsumcat.iloc[:,10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfsumnum=df.describe(include=[np.number])\n",
    "dfsumnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()/len(df)<0.30 #make sure at least 70 percent of data is present!\n",
    "#terror_data['injuries'] = terror_data['injuries'].fillna(0).astype(int)\n",
    "df.isnull().sum()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)  Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_many_cat=df.select_dtypes(include=['category']).apply(lambda x: len(x.unique())>12)\n",
    "#1. data has many categories: label na data as missing\n",
    "df_cat_hi=df.select_dtypes(include=['category']).ix[:,col_many_cat==True] \n",
    "df_cat_hi=df_cat_hi.apply(lambda x: x.cat.add_categories(['missing']).fillna('missing'))\n",
    "#2  data has few categories:impute na data as most frequent\n",
    "df_cat_lw=df.select_dtypes(include=['category']).ix[:,col_many_cat==False] \n",
    "df_cat_lw=df_cat_lw.apply(lambda x:x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3  data is numerical:impute na data as median (some of the data is skewed)\n",
    "df_num=df[[\"extended\",\"ncasualities\",\"iyear\",\"imonth\",\"latitude\",\"longitude\"]].apply(lambda x:x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_num,df_cat_hi,df_cat_lw],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modify data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"ncasualities\"]=list(np.log10(np.array((df[\"ncasualities\"]))+1))\n",
    "setcrit=zip(list(df[\"crit1\"]),list(df[\"crit2\"]),list(df[\"crit3\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"critall\"]=[str(s[0])+str(s[1])+str(s[2]) for s in setcrit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['critall']=df['critall'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Spatial Terrorism Hot Zones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geopy.distance import great_circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define coordinates \n",
    "coords = df.as_matrix(columns=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subcoords=coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kms_per_radian = 6371.0088 #haversine needs radians\n",
    "epsilon = 160 / kms_per_radian # otherwise outside of cluster (100 miles)\n",
    "db = DBSCAN(eps=epsilon, min_samples=1, algorithm='ball_tree', metric='haversine').fit(np.radians(subcoords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_labels = db.labels_\n",
    "num_clusters = len(set(cluster_labels))\n",
    "clusters = pd.Series([subcoords[cluster_labels == n] for n in range(num_clusters)])\n",
    "print('Number of clusters: {}'.format(num_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"terrorism_hotspot\"]=list(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"terrorism_hotspot\"]=df[\"terrorism_hotspot\"].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) refine model and drop columns that are adding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df.drop([\"individual\",\"crit1\",\"suicide\",\"ishostkid\",\"latitude\",\"longitude\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training and Testing Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. splice out data that has no group assigned to the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfgu=df.ix[df['gname']=='Unknown',:] #group unknown\n",
    "dfgk=df.ix[df['gname']!='Unknown',:]#group known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df)==len(dfgu)+len(dfgk) #check that this is all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. factorize categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of the feature column's names\n",
    "dfgk_cat=dfgk.select_dtypes(include=['category']).apply(lambda x: pd.factorize(x)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfgk_num=dfgk.select_dtypes(exclude=['category'])\n",
    "dfgk_fac = pd.concat([dfgk_cat,dfgk_num], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. split data training and test  sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomly label some rows as training and some as test data.\n",
    "dfgk_fac['is_train'] = np.random.uniform(0, 1, len(dfgk_fac)) <= .70 #is train? 1/0 (75% training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = dfgk_fac[dfgk_fac['is_train']==True], dfgk_fac[dfgk_fac['is_train']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the number of observations\n",
    "train=train.drop(\"is_train\",axis=1)\n",
    "test=test.drop(\"is_train\",axis=1)\n",
    "print('total attacks in the training data:', len(train))\n",
    "print('total attacks in the test data:',len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=train[\"gname\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of the feature column's names\n",
    "features = train.drop('gname',axis=1).columns[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generated a random forest classifer (clf)\n",
    "clf = RandomForestClassifier(n_jobs=4,max_depth=15,random_state=0,warm_start=False,oob_score=False,n_estimators=30)\n",
    "# training the classifer on the terrorist group names\n",
    "clf.fit(train[features],y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test Model on Data Piecewise to Avoid Memory Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test subset of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pull of a subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "div20=27500\n",
    "mytest=test.iloc[0:div20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write function that will predict given index of attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predset(index_attack):\n",
    "    return clf.predict(mytest[features].iloc[index_attack,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create an index set for attacks (20 in each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mysets=np.reshape(np.arange(0,div20),(div20/20,20)) #test 20 at a time\n",
    "preds=np.zeros(div20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have the model predict the group responsible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for set_index in mysets:\n",
    "    preds[set_index]=predset(set_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see how accurate the predictions were"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(mytest['gname'], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "#conf=pd.crosstab(mytest['gname'], preds, rownames=['Actual Group Name'], colnames=['Predicted Group Name'])\n",
    "plt.rcParams['figure.figsize'] = [12, 7]\n",
    "conf = confusion_matrix(mytest['gname'],preds)\n",
    "plt.imshow(conf[1:10,1:10],interpolation='None',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list(zip(train[features], clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "findex = np.argsort(importances)\n",
    "plt.rcParams['figure.figsize'] = [12, 7]\n",
    "plt.figure(1)\n",
    "plt.title('The Importance of the Predictors')\n",
    "plt.barh(range(len(findex)), importances[findex], color='g', align='center')\n",
    "plt.yticks(range(len(findex)), features[findex])\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hack to Give us OOB score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generated a random forest classifer (clf)\n",
    "clf = RandomForestClassifier(n_jobs=4,max_depth=15,random_state=0,warm_start=True,oob_score=True,n_estimators=1)\n",
    "# training the classifer on the terrorist group names\n",
    "clf.fit(train[features].iloc[0:2000],y[0:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1-clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is close to what we found when we tested our model on data it had never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
